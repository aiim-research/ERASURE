{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle file \n",
    "\n",
    "import pickle\n",
    "\n",
    "path = \"resources/data/cifar-100-python/meta\"\n",
    "with open(path, 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "\n",
    "print(pickle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of 'boy', sunflowers, apples, couch, bee, lion, plain, turtle, hamster, pine\n",
    "\n",
    "fine_label_names = pickle_data['fine_label_names']\n",
    "\n",
    "words_to_find = ['boy', 'sunflower', 'apple', 'couch', 'bee', 'lion', 'plain', 'turtle', 'hamster', 'pine_tree']\n",
    "\n",
    "for word in words_to_find:\n",
    "    print(f\"Index of {word}: {fine_label_names.index(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import resnet \n",
    "from torchvision import models\n",
    "resnet18 = models.resnet18()\n",
    "\n",
    "# import cifar-100 dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "path = \"resources/data/cifar-100-python/train\"\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    cifar100 = pickle.load(f, encoding='bytes')\n",
    "\n",
    "print(cifar100.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cifar100 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR100(root='resources/data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR100(root='resources/data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_samples = []\n",
    "forget_samples = []\n",
    "for elem in trainset: \n",
    "    if elem[1] == 11:\n",
    "        forget_samples.append(elem)\n",
    "    else:\n",
    "        retain_samples.append(elem)\n",
    "\n",
    "len(retain_samples), len(forget_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar100_fine_to_coarse_idx(fine_idx):\n",
    "    # Mapping from fine labels (0-99) to coarse labels (0-19) based on CIFAR-100 dataset\n",
    "    fine_to_coarse = [\n",
    "        4, 1, 14, 8, 0, 6, 7, 7, 18, 3,\n",
    "        3, 14, 9, 18, 7, 11, 3, 9, 7, 11,\n",
    "        6, 11, 5, 10, 7, 6, 13, 15, 3, 15,\n",
    "        0, 11, 1, 10, 12, 14, 16, 9, 11, 5,\n",
    "        5, 19, 8, 8, 15, 13, 14, 17, 18, 10,\n",
    "        16, 4, 17, 4, 2, 0, 17, 4, 18, 17,\n",
    "        10, 3, 2, 12, 12, 16, 12, 1, 9, 19,\n",
    "        2, 10, 0, 1, 16, 12, 9, 13, 15, 13,\n",
    "        16, 19, 2, 4, 6, 19, 5, 5, 8, 19,\n",
    "        18, 1, 2, 15, 6, 0, 17, 8, 14, 13\n",
    "    ]\n",
    "    \n",
    "    return fine_to_coarse[fine_idx]\n",
    "\n",
    "# Example usage:\n",
    "fine_label_idx = 23  # Example fine label index\n",
    "coarse_label_idx = cifar100_fine_to_coarse_idx(fine_label_idx)\n",
    "print(f\"Fine label {fine_label_idx} maps to coarse label {coarse_label_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two datasets for retain and forget samples\n",
    "class Cifar100Dataset:\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.samples[idx][0]\n",
    "        y = cifar100_fine_to_coarse_idx(self.samples[idx][1])\n",
    "        return x, y\n",
    "\n",
    "train_dataset = Cifar100Dataset(trainset)\n",
    "test_dataset = Cifar100Dataset(testset)\n",
    "\n",
    "\n",
    "retain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "imshow(trainset[0][0])\n",
    "print(trainset[0][1])\n",
    "print(trainset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet model \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet18 = models.resnet18()\n",
    "resnet18.fc = nn.Linear(512, 20)\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "# training loop\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in tqdm(range(10)):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(retain_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet18(inputs.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 2000 == 1999:\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 2000}\")\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on the forget set \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = resnet18(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on forget set: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on forget set: 95.74%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in retain_loader:\n",
    "        images, labels = data\n",
    "        outputs = resnet18(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on forget set: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csavelli/miniconda3/envs/hf_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'artist', 'genre', 'style'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"huggan/wikiart\")\n",
    "# get the first 1000 samples\n",
    "dataset = dataset['train'].select(range(2000))\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "to_keep = [12, 21]\n",
    "\n",
    "df_filtered = df[df['style'].isin(to_keep)]\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 image  artist  genre  style\n",
      "0    <PIL.JpegImagePlugin.JpegImageFile image mode=...      22      4     21\n",
      "1    <PIL.JpegImagePlugin.JpegImageFile image mode=...      17      2     12\n",
      "2    <PIL.JpegImagePlugin.JpegImageFile image mode=...      22     10     21\n",
      "3    <PIL.JpegImagePlugin.JpegImageFile image mode=...      11      6     21\n",
      "4    <PIL.JpegImagePlugin.JpegImageFile image mode=...       1      6     21\n",
      "..                                                 ...     ...    ...    ...\n",
      "959  <PIL.JpegImagePlugin.JpegImageFile image mode=...      22      8     21\n",
      "960  <PIL.JpegImagePlugin.JpegImageFile image mode=...       1      6     21\n",
      "961  <PIL.JpegImagePlugin.JpegImageFile image mode=...      17      4     12\n",
      "962  <PIL.JpegImagePlugin.JpegImageFile image mode=...      11     10     12\n",
      "963  <PIL.JpegImagePlugin.JpegImageFile image mode=...       6      2     12\n",
      "\n",
      "[964 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# filter only the paintings with a particular style \n",
    "\n",
    "to_keep = [12, 21]\n",
    "\n",
    "df_filtered = df[df['style'].isin(to_keep)]\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# convert back to dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mdf_filtered\u001b[49m\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_filtered\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "# convert back to dataset\n",
    "df_filtered = df_filtered.to_dict('records')\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1451 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  artist  genre  style\n",
       "0     <PIL.JpegImagePlugin.JpegImageFile image mode=...      22      4      1\n",
       "1     <PIL.JpegImagePlugin.JpegImageFile image mode=...      17      2      0\n",
       "2     <PIL.JpegImagePlugin.JpegImageFile image mode=...      22     10      1\n",
       "3     <PIL.JpegImagePlugin.JpegImageFile image mode=...      11      6      1\n",
       "4     <PIL.JpegImagePlugin.JpegImageFile image mode=...       1      6      1\n",
       "...                                                 ...     ...    ...    ...\n",
       "1446  <PIL.JpegImagePlugin.JpegImageFile image mode=...       6      2      1\n",
       "1447  <PIL.JpegImagePlugin.JpegImageFile image mode=...       5      5      0\n",
       "1448  <PIL.JpegImagePlugin.JpegImageFile image mode=...       1     10      1\n",
       "1449  <PIL.JpegImagePlugin.JpegImageFile image mode=...       5      2      0\n",
       "1450  <PIL.JpegImagePlugin.JpegImageFile image mode=...       2      6      0\n",
       "\n",
       "[1451 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the labels between 0 and 5 \n",
    "df_filtered['style'] = df_filtered['style'].apply(lambda x: to_keep.index(x))\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "style\n",
      "0    849\n",
      "1    602\n",
      "Name: count, dtype: int64\n",
      "artist\n",
      "17    214\n",
      "4     191\n",
      "22    154\n",
      "11    120\n",
      "2     117\n",
      "5     100\n",
      "8      93\n",
      "6      86\n",
      "3      86\n",
      "1      78\n",
      "10     74\n",
      "18     63\n",
      "16     19\n",
      "13     19\n",
      "14     15\n",
      "21     14\n",
      "15      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# keep only the top 6 labels and remove the rest from the dataset \n",
    "print(df_filtered['style'].value_counts())\n",
    "\n",
    "# select top artists for images in the dataset with their style \n",
    "artists = df_filtered['artist'].value_counts()\n",
    "print(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "style\n",
       "0    19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[df_filtered['artist'] == 16]['style'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist 3 total styles count: 86\n",
      "style\n",
      "0    86\n",
      "Name: count, dtype: int64\n",
      "Artist 16 total styles count: 19\n",
      "style\n",
      "0    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check artist 22 \n",
    "for num in [3, 16]:\n",
    "    style_counts = df_filtered[df_filtered['artist'] == num]['style'].value_counts()\n",
    "    total_images_removed = style_counts.sum()\n",
    "    print(f\"Artist {num} total styles count: {total_images_removed}\")\n",
    "    print(style_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tensor with artist and then style \n",
    "import torch \n",
    "sample = dataset[\"train\"][0]\n",
    "\n",
    "label = torch.tensor([sample[\"artist\"], sample[\"style\"]])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image to tensor \n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    #transforms.ToTensor()\n",
    "])\n",
    "for sample in dataset[\"train\"]:\n",
    "    image = sample[\"image\"]\n",
    "    tensor_image = transform(image)\n",
    "    break\n",
    "\n",
    "transform(dataset[\"train\"][3][\"image\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
