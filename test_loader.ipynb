{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764b5f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NFSHOME/adangelo/miniconda3/envs/representer/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import argparse\n",
    "from erasure.utils.logger import GLogger\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import tracemalloc\n",
    "from erasure.utils.config.local_ctx import Local\n",
    "from erasure.utils.config.global_ctx import Global, bcolors \n",
    "from erasure.core.factory_base import ConfigurableFactory\n",
    "from erasure.data.datasets.DatasetManager import DatasetManager\n",
    "tracemalloc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(\"configs\",\"resource\",\"PROTEINS.jsonc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb91986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-31 16:28:00,649990589 | INFO | 2636473 - Creating Global Context for: configs/resource/BACE.jsonc\n",
      "2025-05-31 16:28:00,649990616 | INFO | 2636473 - Setting seeds to: 0\n",
      "2025-05-31 16:28:00,649990633 | INFO | 2636473 - \u001b[91mCaching System: False.\u001b[0m\n",
      "2025-05-31 16:28:00,649990642 | INFO | 2636473 - Instantiating: torch_geometric.datasets.MoleculeNet\n",
      "2025-05-31 16:28:00,649990724 | INFO | 2636473 - Created Configurable: erasure.data.data_sources.TorchGeometricDataSource.TorchGeometricDataSource\n",
      "2025-05-31 16:28:00,649990726 | INFO | 2636473 - {'class': 'erasure.data.data_sources.TorchGeometricDataSource.TorchGeometricDataSource', 'parameters': {'datasource': {'class': 'torch_geometric.datasets.MoleculeNet', 'parameters': {'root': 'resources/data', 'name': 'BACE'}, 'preprocess': []}}}\n",
      "2025-05-31 16:28:01,649991921 | INFO | 2636473 - Instantiating: erasure.data.datasets.DataSplitter.DataSplitterPercentage\n",
      "2025-05-31 16:28:01,649992009 | INFO | 2636473 - ['all', 'all_shuffled', '-']\n",
      "2025-05-31 16:28:01,649992011 | INFO | 2636473 - Instantiating: erasure.data.datasets.DataSplitter.DataSplitterPercentage\n",
      "2025-05-31 16:28:01,649992013 | INFO | 2636473 - ['all', 'all_shuffled', '-', 'train', 'test']\n",
      "2025-05-31 16:28:01,649992015 | INFO | 2636473 - Instantiating: erasure.data.datasets.DataSplitter.DataSplitterPercentage\n",
      "2025-05-31 16:28:01,649992017 | INFO | 2636473 - ['all', 'all_shuffled', '-', 'train', 'test', 'forget', 'retain']\n",
      "2025-05-31 16:28:01,649992019 | INFO | 2636473 - ['all', 'all_shuffled', '-', 'train', 'test', 'forget', 'retain']\n",
      "2025-05-31 16:28:01,649992020 | INFO | 2636473 - Created Configurable: erasure.data.datasets.DatasetManager.DatasetManager\n"
     ]
    }
   ],
   "source": [
    "global_ctx = Global(config_file)\n",
    "global_ctx.factory = ConfigurableFactory(global_ctx)\n",
    "\n",
    "#Create Dataset\n",
    "data_manager = global_ctx.factory.get_object( Local( global_ctx.config.data ))\n",
    "global_ctx.dataset = data_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47050ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-31 16:28:03,649994088 | INFO | 2636473 - Instantiating: erasure.model.gcn.DownstreamGCN\n",
      "2025-05-31 16:28:03,649994098 | INFO | 2636473 - Instantiating: torch.optim.RMSprop\n",
      "2025-05-31 16:28:03,649994102 | INFO | 2636473 - Instantiating: torch.nn.CrossEntropyLoss\n",
      "2025-05-31 16:28:03,649994105 | INFO | 2636473 - TRAINING WITH 1210 samples\n",
      "2025-05-31 16:28:05,649996286 | INFO | 2636473 - epoch = 0 ---> loss = 0.7087\t accuracy = 0.4992\n",
      "2025-05-31 16:28:07,649998387 | INFO | 2636473 - epoch = 1 ---> loss = 0.6940\t accuracy = 0.5116\n",
      "2025-05-31 16:28:09,650000516 | INFO | 2636473 - epoch = 2 ---> loss = 0.6896\t accuracy = 0.5281\n",
      "2025-05-31 16:28:12,650002593 | INFO | 2636473 - epoch = 3 ---> loss = 0.6858\t accuracy = 0.5447\n",
      "2025-05-31 16:28:14,650004736 | INFO | 2636473 - epoch = 4 ---> loss = 0.6822\t accuracy = 0.5546\n",
      "2025-05-31 16:28:16,650006818 | INFO | 2636473 - epoch = 5 ---> loss = 0.6792\t accuracy = 0.5679\n",
      "2025-05-31 16:28:18,650008848 | INFO | 2636473 - epoch = 6 ---> loss = 0.6753\t accuracy = 0.5737\n",
      "2025-05-31 16:28:20,650010887 | INFO | 2636473 - epoch = 7 ---> loss = 0.6719\t accuracy = 0.5877\n",
      "2025-05-31 16:28:22,650012959 | INFO | 2636473 - epoch = 8 ---> loss = 0.6687\t accuracy = 0.5919\n",
      "2025-05-31 16:28:24,650015057 | INFO | 2636473 - epoch = 9 ---> loss = 0.6658\t accuracy = 0.5952\n",
      "2025-05-31 16:28:26,650017142 | INFO | 2636473 - epoch = 10 ---> loss = 0.6629\t accuracy = 0.6051\n",
      "2025-05-31 16:28:28,650019195 | INFO | 2636473 - epoch = 11 ---> loss = 0.6604\t accuracy = 0.6142\n",
      "2025-05-31 16:28:30,650021244 | INFO | 2636473 - epoch = 12 ---> loss = 0.6579\t accuracy = 0.6175\n",
      "2025-05-31 16:28:32,650023296 | INFO | 2636473 - epoch = 13 ---> loss = 0.6553\t accuracy = 0.6184\n",
      "2025-05-31 16:28:34,650025355 | INFO | 2636473 - epoch = 14 ---> loss = 0.6529\t accuracy = 0.6184\n",
      "2025-05-31 16:28:36,650027445 | INFO | 2636473 - epoch = 15 ---> loss = 0.6509\t accuracy = 0.6250\n",
      "2025-05-31 16:28:38,650029522 | INFO | 2636473 - epoch = 16 ---> loss = 0.6487\t accuracy = 0.6291\n",
      "2025-05-31 16:28:41,650031596 | INFO | 2636473 - epoch = 17 ---> loss = 0.6467\t accuracy = 0.6349\n",
      "2025-05-31 16:28:43,650033767 | INFO | 2636473 - epoch = 18 ---> loss = 0.6449\t accuracy = 0.6349\n",
      "2025-05-31 16:28:45,650035824 | INFO | 2636473 - epoch = 19 ---> loss = 0.6431\t accuracy = 0.6432\n",
      "2025-05-31 16:28:45,650035827 | INFO | 2636473 - TorchModel trained on cpu in: 41.72284531593323 secs\n",
      "2025-05-31 16:28:45,650035829 | INFO | 2636473 - Created Configurable: erasure.model.TorchModel.TorchModel\n",
      "2025-05-31 16:28:45,650035832 | INFO | 2636473 - Global Predictor: <erasure.model.TorchModel.TorchModel object at 0x7fd1bfeea550>\n"
     ]
    }
   ],
   "source": [
    "#Create Predictor\n",
    "current = Local(global_ctx.config.predictor)\n",
    "current.dataset = data_manager\n",
    "predictor = global_ctx.factory.get_object(current)\n",
    "global_ctx.predictor = predictor\n",
    "global_ctx.logger.info('Global Predictor: ' + str(predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7983993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-29 20:27:18,491549508 | INFO | 1627775 - Created Configurable: erasure.unlearners.composite.Identity\n",
      "2025-05-29 20:27:19,491550204 | INFO | 1627775 - Created Configurable: erasure.unlearners.GoldModel.GoldModel\n",
      "2025-05-29 20:27:20,491550897 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:20,491550903 | INFO | 1627775 - Created Configurable: erasure.unlearners.Finetuning.Finetuning\n",
      "2025-05-29 20:27:21,491551628 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:21,491551631 | INFO | 1627775 - Created Configurable: erasure.unlearners.Finetuning.Finetuning\n",
      "2025-05-29 20:27:21,491552315 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:21,491552318 | INFO | 1627775 - Created Configurable: erasure.unlearners.Finetuning.Finetuning\n",
      "2025-05-29 20:27:22,491553029 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:22,491553034 | INFO | 1627775 - Created Configurable: erasure.unlearners.SuccessiveRandomLabels.SuccessiveRandomLabels\n",
      "2025-05-29 20:27:23,491553748 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:23,491553752 | INFO | 1627775 - Created Configurable: erasure.unlearners.SuccessiveRandomLabels.SuccessiveRandomLabels\n",
      "2025-05-29 20:27:23,491554457 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:23,491554461 | INFO | 1627775 - Created Configurable: erasure.unlearners.SuccessiveRandomLabels.SuccessiveRandomLabels\n",
      "2025-05-29 20:27:24,491555156 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:24,491555159 | INFO | 1627775 - Created Configurable: erasure.unlearners.Finetuning.Finetuning\n",
      "2025-05-29 20:27:25,491555869 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:25,491555872 | INFO | 1627775 - Created Configurable: erasure.unlearners.Finetuning.Finetuning\n",
      "2025-05-29 20:27:26,491556598 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:26,491556601 | INFO | 1627775 - Created Configurable: erasure.unlearners.Finetuning.Finetuning\n",
      "2025-05-29 20:27:26,491557304 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:26,491557311 | INFO | 1627775 - Created Configurable: erasure.unlearners.eu_k.eu_k\n",
      "2025-05-29 20:27:28,491558900 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:28,491558904 | INFO | 1627775 - Created Configurable: erasure.unlearners.eu_k.eu_k\n",
      "2025-05-29 20:27:29,491559583 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:29,491559586 | INFO | 1627775 - Created Configurable: erasure.unlearners.eu_k.eu_k\n",
      "2025-05-29 20:27:29,491560260 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:29,491560263 | INFO | 1627775 - Created Configurable: erasure.unlearners.NegGrad.NegGrad\n",
      "2025-05-29 20:27:30,491560920 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:30,491560923 | INFO | 1627775 - Created Configurable: erasure.unlearners.NegGrad.NegGrad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-29 20:27:31,491561605 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:31,491561608 | INFO | 1627775 - Created Configurable: erasure.unlearners.NegGrad.NegGrad\n",
      "2025-05-29 20:27:31,491562289 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:31,491562292 | INFO | 1627775 - Created Configurable: erasure.unlearners.AdvancedNegGrad.AdvancedNegGrad\n",
      "2025-05-29 20:27:32,491562987 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:32,491562990 | INFO | 1627775 - Created Configurable: erasure.unlearners.AdvancedNegGrad.AdvancedNegGrad\n",
      "2025-05-29 20:27:33,491563682 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:33,491563685 | INFO | 1627775 - Created Configurable: erasure.unlearners.AdvancedNegGrad.AdvancedNegGrad\n",
      "2025-05-29 20:27:33,491564359 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:33,491564362 | INFO | 1627775 - Created Configurable: erasure.unlearners.UNSIR.UNSIR\n",
      "2025-05-29 20:27:33,491564364 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:33,491564366 | INFO | 1627775 - Created Configurable: erasure.unlearners.Finetuning.Finetuning\n",
      "2025-05-29 20:27:33,491564367 | INFO | 1627775 - Created Configurable: erasure.unlearners.composite.Cascade\n",
      "2025-05-29 20:27:34,491565049 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:34,491565052 | INFO | 1627775 - Created Configurable: erasure.unlearners.UNSIR.UNSIR\n",
      "2025-05-29 20:27:34,491565054 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:34,491565056 | INFO | 1627775 - Created Configurable: erasure.unlearners.Finetuning.Finetuning\n",
      "2025-05-29 20:27:34,491565061 | INFO | 1627775 - Created Configurable: erasure.unlearners.composite.Cascade\n",
      "2025-05-29 20:27:35,491565752 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:35,491565755 | INFO | 1627775 - Created Configurable: erasure.unlearners.UNSIR.UNSIR\n",
      "2025-05-29 20:27:35,491565760 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:35,491565770 | INFO | 1627775 - Created Configurable: erasure.unlearners.Finetuning.Finetuning\n",
      "2025-05-29 20:27:35,491565771 | INFO | 1627775 - Created Configurable: erasure.unlearners.composite.Cascade\n",
      "2025-05-29 20:27:35,491566468 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:35,491566471 | INFO | 1627775 - Created Configurable: erasure.unlearners.BadTeaching.BadTeaching\n",
      "2025-05-29 20:27:36,491567155 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:36,491567158 | INFO | 1627775 - Created Configurable: erasure.unlearners.BadTeaching.BadTeaching\n",
      "2025-05-29 20:27:37,491567829 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:37,491567832 | INFO | 1627775 - Created Configurable: erasure.unlearners.BadTeaching.BadTeaching\n",
      "2025-05-29 20:27:37,491568527 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:38,491568529 | INFO | 1627775 - Created Configurable: erasure.unlearners.Scrub.Scrub\n",
      "2025-05-29 20:27:38,491569203 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:38,491569206 | INFO | 1627775 - Created Configurable: erasure.unlearners.Scrub.Scrub\n",
      "2025-05-29 20:27:39,491569879 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:39,491569883 | INFO | 1627775 - Created Configurable: erasure.unlearners.Scrub.Scrub\n",
      "2025-05-29 20:27:40,491570547 | INFO | 1627775 - Created Configurable: erasure.unlearners.FisherForgetting.FisherForgetting\n",
      "2025-05-29 20:27:40,491571214 | INFO | 1627775 - Created Configurable: erasure.unlearners.FisherForgetting.FisherForgetting\n",
      "2025-05-29 20:27:42,491572797 | INFO | 1627775 - Created Configurable: erasure.unlearners.FisherForgetting.FisherForgetting\n",
      "2025-05-29 20:27:42,491573483 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:42,491573487 | INFO | 1627775 - Created Configurable: erasure.unlearners.SelectiveSynapticDampening.SelectiveSynapticDampening\n",
      "2025-05-29 20:27:43,491574171 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:43,491574174 | INFO | 1627775 - Created Configurable: erasure.unlearners.SelectiveSynapticDampening.SelectiveSynapticDampening\n",
      "2025-05-29 20:27:44,491574872 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:44,491574875 | INFO | 1627775 - Created Configurable: erasure.unlearners.SelectiveSynapticDampening.SelectiveSynapticDampening\n",
      "2025-05-29 20:27:45,491575572 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:45,491575578 | INFO | 1627775 - Created Configurable: erasure.unlearners.SaliencyMapGeneration.SaliencyMapGeneration\n",
      "2025-05-29 20:27:45,491575579 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:45,491575583 | INFO | 1627775 - Created Configurable: erasure.unlearners.SuccessiveRandomLabels.SuccessiveRandomLabels\n",
      "2025-05-29 20:27:45,491575584 | INFO | 1627775 - Created Configurable: erasure.unlearners.composite.Cascade\n",
      "2025-05-29 20:27:45,491576267 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:45,491576276 | INFO | 1627775 - Created Configurable: erasure.unlearners.SaliencyMapGeneration.SaliencyMapGeneration\n",
      "2025-05-29 20:27:45,491576277 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:45,491576280 | INFO | 1627775 - Created Configurable: erasure.unlearners.SuccessiveRandomLabels.SuccessiveRandomLabels\n",
      "2025-05-29 20:27:45,491576281 | INFO | 1627775 - Created Configurable: erasure.unlearners.composite.Cascade\n",
      "2025-05-29 20:27:46,491576972 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:46,491576981 | INFO | 1627775 - Created Configurable: erasure.unlearners.SaliencyMapGeneration.SaliencyMapGeneration\n",
      "2025-05-29 20:27:46,491576983 | INFO | 1627775 - Instantiating: torch.optim.Adam\n",
      "2025-05-29 20:27:46,491576987 | INFO | 1627775 - Created Configurable: erasure.unlearners.SuccessiveRandomLabels.SuccessiveRandomLabels\n",
      "2025-05-29 20:27:46,491576991 | INFO | 1627775 - Created Configurable: erasure.unlearners.composite.Cascade\n",
      "2025-05-29 20:27:46,491576993 | INFO | 1627775 - Created Configurable: erasure.evaluations.running.RunTime\n",
      "2025-05-29 20:27:46,491577002 | INFO | 1627775 - Function: <function accuracy_score at 0x7feaaef23430>\n",
      "2025-05-29 20:27:46,491577003 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.TorchSKLearn\n",
      "2025-05-29 20:27:46,491577011 | INFO | 1627775 - Function: <function accuracy_score at 0x7feaaef23430>\n",
      "2025-05-29 20:27:46,491577012 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.TorchSKLearn\n",
      "2025-05-29 20:27:46,491577016 | INFO | 1627775 - Function: <function accuracy_score at 0x7feaaef23430>\n",
      "2025-05-29 20:27:46,491577019 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.TorchSKLearn\n",
      "2025-05-29 20:27:46,491577028 | INFO | 1627775 - Function: <function accuracy_score at 0x7feaaef23430>\n",
      "2025-05-29 20:27:46,491577029 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.TorchSKLearn\n",
      "2025-05-29 20:27:46,491577037 | INFO | 1627775 - Function: <function accuracy_score at 0x7feaaef23430>\n",
      "2025-05-29 20:27:46,491577038 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.TorchSKLearn\n",
      "2025-05-29 20:27:46,491577041 | INFO | 1627775 - Function: <function accuracy_score at 0x7feaaef23430>\n",
      "2025-05-29 20:27:46,491577042 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.TorchSKLearn\n",
      "2025-05-29 20:27:46,491577043 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.AUS\n",
      "2025-05-29 20:27:46,491577045 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.RelearnTime\n",
      "2025-05-29 20:27:46,491577046 | INFO | 1627775 - Created Configurable: erasure.unlearners.GoldModel.GoldModel\n",
      "2025-05-29 20:27:46,491577048 | INFO | 1627775 - Unlearning copyed predictor: global\n",
      "2025-05-29 20:27:46,491577051 | INFO | 1627775 - Instantiating: erasure.model.gcn.DownstreamGCN\n",
      "2025-05-29 20:27:46,491577059 | INFO | 1627775 - Instantiating: torch.optim.RMSprop\n",
      "2025-05-29 20:27:46,491577061 | INFO | 1627775 - Instantiating: torch.nn.CrossEntropyLoss\n",
      "2025-05-29 20:27:47,491578238 | INFO | 1627775 - epoch = 0 ---> loss = 0.6767\t accuracy = 0.5969\n",
      "2025-05-29 20:27:48,491579362 | INFO | 1627775 - epoch = 1 ---> loss = 0.6741\t accuracy = 0.5997\n",
      "2025-05-29 20:27:49,491580492 | INFO | 1627775 - epoch = 2 ---> loss = 0.6736\t accuracy = 0.5997\n",
      "2025-05-29 20:27:51,491581652 | INFO | 1627775 - epoch = 3 ---> loss = 0.6732\t accuracy = 0.5997\n",
      "2025-05-29 20:27:52,491582799 | INFO | 1627775 - epoch = 4 ---> loss = 0.6728\t accuracy = 0.5997\n",
      "2025-05-29 20:27:53,491583962 | INFO | 1627775 - epoch = 5 ---> loss = 0.6724\t accuracy = 0.5997\n",
      "2025-05-29 20:27:54,491585157 | INFO | 1627775 - epoch = 6 ---> loss = 0.6718\t accuracy = 0.5997\n",
      "2025-05-29 20:27:55,491586358 | INFO | 1627775 - epoch = 7 ---> loss = 0.6712\t accuracy = 0.5997\n",
      "2025-05-29 20:27:57,491587709 | INFO | 1627775 - epoch = 8 ---> loss = 0.6704\t accuracy = 0.5997\n",
      "2025-05-29 20:27:58,491588895 | INFO | 1627775 - epoch = 9 ---> loss = 0.6696\t accuracy = 0.5997\n",
      "2025-05-29 20:27:59,491590031 | INFO | 1627775 - epoch = 10 ---> loss = 0.6688\t accuracy = 0.5997\n",
      "2025-05-29 20:28:00,491591162 | INFO | 1627775 - epoch = 11 ---> loss = 0.6677\t accuracy = 0.5997\n",
      "2025-05-29 20:28:01,491592329 | INFO | 1627775 - epoch = 12 ---> loss = 0.6670\t accuracy = 0.5997\n",
      "2025-05-29 20:28:02,491593490 | INFO | 1627775 - epoch = 13 ---> loss = 0.6661\t accuracy = 0.5997\n",
      "2025-05-29 20:28:04,491594651 | INFO | 1627775 - epoch = 14 ---> loss = 0.6654\t accuracy = 0.5997\n",
      "2025-05-29 20:28:05,491595819 | INFO | 1627775 - epoch = 15 ---> loss = 0.6646\t accuracy = 0.5997\n",
      "2025-05-29 20:28:06,491596985 | INFO | 1627775 - epoch = 16 ---> loss = 0.6638\t accuracy = 0.5997\n",
      "2025-05-29 20:28:07,491598166 | INFO | 1627775 - epoch = 17 ---> loss = 0.6629\t accuracy = 0.5997\n",
      "2025-05-29 20:28:08,491599381 | INFO | 1627775 - epoch = 18 ---> loss = 0.6620\t accuracy = 0.5997\n",
      "2025-05-29 20:28:10,491600555 | INFO | 1627775 - epoch = 19 ---> loss = 0.6611\t accuracy = 0.5997\n",
      "2025-05-29 20:28:11,491601711 | INFO | 1627775 - epoch = 20 ---> loss = 0.6600\t accuracy = 0.6096\n",
      "2025-05-29 20:28:12,491602863 | INFO | 1627775 - epoch = 21 ---> loss = 0.6591\t accuracy = 0.6236\n",
      "2025-05-29 20:28:13,491603980 | INFO | 1627775 - epoch = 22 ---> loss = 0.6581\t accuracy = 0.6222\n",
      "2025-05-29 20:28:14,491605193 | INFO | 1627775 - epoch = 23 ---> loss = 0.6572\t accuracy = 0.6222\n",
      "2025-05-29 20:28:15,491606370 | INFO | 1627775 - epoch = 24 ---> loss = 0.6562\t accuracy = 0.6250\n",
      "2025-05-29 20:28:17,491607603 | INFO | 1627775 - epoch = 25 ---> loss = 0.6553\t accuracy = 0.6278\n",
      "2025-05-29 20:28:18,491608790 | INFO | 1627775 - epoch = 26 ---> loss = 0.6543\t accuracy = 0.6278\n",
      "2025-05-29 20:28:19,491609978 | INFO | 1627775 - epoch = 27 ---> loss = 0.6534\t accuracy = 0.6320\n",
      "2025-05-29 20:28:20,491611178 | INFO | 1627775 - epoch = 28 ---> loss = 0.6524\t accuracy = 0.6306\n",
      "2025-05-29 20:28:21,491612423 | INFO | 1627775 - epoch = 29 ---> loss = 0.6514\t accuracy = 0.6334\n",
      "2025-05-29 20:28:21,491612431 | INFO | 1627775 - TorchModel trained on cpu in: 35.36742353439331 secs\n",
      "2025-05-29 20:28:21,491612435 | INFO | 1627775 - \u001b[91mDumped Instance to: \u001b[4mresources/cached/erasure.model.gcn.DownstreamGCN-cd4b80f185fdf16194c133edef216533\u001b[0m\n",
      "2025-05-29 20:28:39,491629565 | INFO | 1627775 - Created Configurable: erasure.model.TorchModel.TorchModel\n",
      "2025-05-29 20:28:39,491629570 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.AIN\n",
      "2025-05-29 20:28:39,491629572 | INFO | 1627775 - Instantiating: torch.nn.CrossEntropyLoss\n",
      "2025-05-29 20:28:39,491629574 | INFO | 1627775 - Created Configurable: erasure.evaluations.MIA.umia.Attack\n",
      "2025-05-29 20:28:39,491629576 | INFO | 1627775 - Created Configurable: erasure.evaluations.measures.SaveValues\n",
      "2025-05-29 20:28:39,491629577 | INFO | 1627775 - Created Configurable: erasure.evaluations.manager.Evaluator\n",
      "2025-05-29 20:28:39,491629588 | INFO | 1627775 - \u001b[92m####\t\t Evaluating Unlearner Identity \t\t####\u001b[0m\n",
      "2025-05-29 20:28:39,491630385 | INFO | 1627775 - Unlearning copyed predictor: <erasure.model.TorchModel.TorchModel object at 0x7fea8904feb0>\n",
      "2025-05-29 20:28:40,491631409 | INFO | 1627775 - sklearn.metrics.accuracy_score of \"test\" on unlearned: 0.6954545454545454 of <erasure.model.TorchModel.TorchModel object at 0x7fea81bc6400>\n",
      "2025-05-29 20:28:41,491631695 | INFO | 1627775 - sklearn.metrics.accuracy_score of \"test\" on original: 0.6954545454545454 of <erasure.model.TorchModel.TorchModel object at 0x7feaa4de3250>\n",
      "2025-05-29 20:28:42,491632802 | INFO | 1627775 - sklearn.metrics.accuracy_score of \"forget\" on unlearned: 0.6534090909090909 of <erasure.model.TorchModel.TorchModel object at 0x7fea8921dd60>\n",
      "2025-05-29 20:28:42,491633072 | INFO | 1627775 - sklearn.metrics.accuracy_score of \"forget\" on original: 0.6534090909090909 of <erasure.model.TorchModel.TorchModel object at 0x7feaa4de3250>\n",
      "2025-05-29 20:28:44,491634820 | INFO | 1627775 - sklearn.metrics.accuracy_score of \"retain\" on unlearned: 0.7401685393258427 of <erasure.model.TorchModel.TorchModel object at 0x7fea818aea90>\n",
      "2025-05-29 20:28:45,491635629 | INFO | 1627775 - sklearn.metrics.accuracy_score of \"retain\" on original: 0.7401685393258427 of <erasure.model.TorchModel.TorchModel object at 0x7feaa4de3250>\n",
      "2025-05-29 20:28:46,491637291 | INFO | 1627775 - Adaptive Unlearning Score: 0.9596510359869139\n",
      "2025-05-29 20:28:48,491638583 | INFO | 1627775 - Relearning Time: 0 epochs\n",
      "2025-05-29 20:29:18,491669148 | INFO | 1627775 - AIN: 9.99900009999e-05\n",
      "2025-05-29 20:29:19,491670037 | INFO | 1627775 - Creating attack dataset\n",
      "2025-05-29 20:29:20,491670558 | INFO | 1627775 - Created Configurable: erasure.data.data_sources.TorchFileDataSource.TorchFileDataSource\n",
      "2025-05-29 20:29:20,491670561 | INFO | 1627775 - {'class': 'erasure.data.data_sources.TorchFileDataSource.TorchFileDataSource', 'parameters': {'path': 'resources/data/umia/umia.pt_2'}}\n",
      "2025-05-29 20:29:20,491670569 | INFO | 1627775 - Instantiating: erasure.data.datasets.DataSplitter.DataSplitterPercentage\n",
      "2025-05-29 20:29:20,491670709 | INFO | 1627775 - ['all', 'train', 'test']\n",
      "2025-05-29 20:29:20,491670711 | INFO | 1627775 - ['all', 'train', 'test']\n",
      "2025-05-29 20:29:20,491670713 | INFO | 1627775 - Created Configurable: erasure.data.datasets.DatasetManager.DatasetManager\n",
      "2025-05-29 20:29:20,491670715 | INFO | 1627775 - Creating attack model\n",
      "2025-05-29 20:29:20,491670791 | INFO | 1627775 - UMIA accuracy: 0.502127659574468\n",
      "2025-05-29 20:29:20,491670796 | INFO | 1627775 - \u001b[92m####\t\t Evaluating Unlearner GoldModel \t\t####\u001b[0m\n",
      "2025-05-29 20:29:21,491671653 | INFO | 1627775 - Unlearning copyed predictor: <erasure.model.TorchModel.TorchModel object at 0x7fea87dff5b0>\n",
      "2025-05-29 20:29:21,491671657 | INFO | 1627775 - Instantiating: erasure.model.gcn.DownstreamGCN\n",
      "2025-05-29 20:29:21,491671668 | INFO | 1627775 - Instantiating: torch.optim.RMSprop\n",
      "2025-05-29 20:29:21,491671677 | INFO | 1627775 - Instantiating: torch.nn.CrossEntropyLoss\n",
      "2025-05-29 20:29:22,491672943 | INFO | 1627775 - epoch = 0 ---> loss = 0.6766\t accuracy = 0.5941\n",
      "2025-05-29 20:29:23,491674272 | INFO | 1627775 - epoch = 1 ---> loss = 0.6732\t accuracy = 0.5997\n",
      "2025-05-29 20:29:25,491675659 | INFO | 1627775 - epoch = 2 ---> loss = 0.6690\t accuracy = 0.5997\n",
      "2025-05-29 20:29:26,491676960 | INFO | 1627775 - epoch = 3 ---> loss = 0.6638\t accuracy = 0.6039\n",
      "2025-05-29 20:29:27,491678167 | INFO | 1627775 - epoch = 4 ---> loss = 0.6577\t accuracy = 0.6404\n",
      "2025-05-29 20:29:28,491679384 | INFO | 1627775 - epoch = 5 ---> loss = 0.6509\t accuracy = 0.6503\n",
      "2025-05-29 20:29:30,491680575 | INFO | 1627775 - epoch = 6 ---> loss = 0.6440\t accuracy = 0.6587\n",
      "2025-05-29 20:29:31,491681914 | INFO | 1627775 - epoch = 7 ---> loss = 0.6370\t accuracy = 0.6601\n",
      "2025-05-29 20:29:32,491683272 | INFO | 1627775 - epoch = 8 ---> loss = 0.6302\t accuracy = 0.6573\n",
      "2025-05-29 20:29:34,491684618 | INFO | 1627775 - epoch = 9 ---> loss = 0.6235\t accuracy = 0.6573\n",
      "2025-05-29 20:29:35,491685996 | INFO | 1627775 - epoch = 10 ---> loss = 0.6173\t accuracy = 0.6587\n",
      "2025-05-29 20:29:36,491687365 | INFO | 1627775 - epoch = 11 ---> loss = 0.6076\t accuracy = 0.6840\n",
      "2025-05-29 20:29:38,491688774 | INFO | 1627775 - epoch = 12 ---> loss = 0.5955\t accuracy = 0.6980\n",
      "2025-05-29 20:29:39,491690128 | INFO | 1627775 - epoch = 13 ---> loss = 0.5862\t accuracy = 0.7135\n",
      "2025-05-29 20:29:40,491691476 | INFO | 1627775 - epoch = 14 ---> loss = 0.5791\t accuracy = 0.7205\n",
      "2025-05-29 20:29:42,491692845 | INFO | 1627775 - epoch = 15 ---> loss = 0.5743\t accuracy = 0.7275\n",
      "2025-05-29 20:29:43,491694036 | INFO | 1627775 - epoch = 16 ---> loss = 0.5703\t accuracy = 0.7275\n",
      "2025-05-29 20:29:44,491695307 | INFO | 1627775 - epoch = 17 ---> loss = 0.5671\t accuracy = 0.7289\n",
      "2025-05-29 20:29:45,491696496 | INFO | 1627775 - epoch = 18 ---> loss = 0.5647\t accuracy = 0.7317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m unlearner \u001b[38;5;129;01min\u001b[39;00m unlearners:\n\u001b[1;32m     17\u001b[0m     global_ctx\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbcolors\u001b[38;5;241m.\u001b[39mOKGREEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m####\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Evaluating Unlearner \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munlearner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m####\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbcolors\u001b[38;5;241m.\u001b[39mENDC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43munlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ERASURE/erasure/evaluations/manager.py:23\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, unlearner, predictor)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m measure \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasures:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m         e \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_ctx\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred during execution of evaluation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeasure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ERASURE/erasure/evaluations/running.py:55\u001b[0m, in \u001b[0;36mRunTime.process\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39munlearned_model:\n\u001b[1;32m     53\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     58\u001b[0m     e\u001b[38;5;241m.\u001b[39madd_value(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunTime\u001b[39m\u001b[38;5;124m'\u001b[39m, metric_value)\n",
      "File \u001b[0;32m~/ERASURE/erasure/evaluations/running.py:24\u001b[0m, in \u001b[0;36mUnlearnRunner.process\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, e: Evaluation):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m         e\u001b[38;5;241m.\u001b[39munlearned_model \u001b[38;5;241m=\u001b[39m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner\u001b[38;5;241m.\u001b[39mprocess(e)\n",
      "File \u001b[0;32m~/ERASURE/erasure/core/unlearner.py:24\u001b[0m, in \u001b[0;36mUnlearner.unlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__preprocess__()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnlearning copyed predictor: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor))\n\u001b[0;32m---> 24\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__unlearn__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__postprocess__()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_model\n",
      "File \u001b[0;32m~/ERASURE/erasure/unlearners/GoldModel.py:27\u001b[0m, in \u001b[0;36mGoldModel.__unlearn__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__unlearn__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    Retrain the model from scratch with a specific (sub)set of the full dataset (usually retain set to evaluate the performance of the model after unlearning)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictor\n",
      "File \u001b[0;32m~/ERASURE/erasure/core/factory_base.py:14\u001b[0m, in \u001b[0;36mConfigurableFactory.get_object\u001b[0;34m(self, local_ctx)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_object\u001b[39m(\u001b[38;5;28mself\u001b[39m, local_ctx):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#self.global_ctx.set_seed(1)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     base_obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated Configurable: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(local_ctx\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base_obj\n",
      "File \u001b[0;32m~/ERASURE/erasure/core/trainable_base.py:12\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, global_ctx, local_ctx)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, global_ctx: Global, local_ctx):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m local_ctx\u001b[38;5;241m.\u001b[39mdataset\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mglobal_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ERASURE/erasure/core/base.py:31\u001b[0m, in \u001b[0;36mConfigurable.__init__\u001b[0;34m(self, global_ctx, local_ctx)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_configuration()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pre_init__():\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__post_init__()\n",
      "File \u001b[0;32m~/ERASURE/erasure/model/TorchModel.py:52\u001b[0m, in \u001b[0;36mTorchModel.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m     \n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ERASURE/erasure/core/trainable_base.py:29\u001b[0m, in \u001b[0;36mTrainable.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     28\u001b[0m     stime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m stime\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/ERASURE/erasure/model/TorchModel.py:65\u001b[0m, in \u001b[0;36mTorchModel.real_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m losses, preds, labels_list \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# print(X)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# print(labels)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     71\u001b[0m     X, labels \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/representer/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/representer/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/representer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/representer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/ERASURE/erasure/data/datasets/Dataset.py:17\u001b[0m, in \u001b[0;36mDatasetWrapper.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     X,y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__realgetitem__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     X,y,Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_preprocessing(X, y, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X,y\n",
      "File \u001b[0;32m~/ERASURE/erasure/data/data_sources/TorchGeometricDataSource.py:19\u001b[0m, in \u001b[0;36mGeometricWrapper.__realgetitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__realgetitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     17\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[0;32m---> 19\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mData\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     y \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39my\n\u001b[1;32m     22\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[0;32m~/miniconda3/envs/representer/lib/python3.9/site-packages/torch_geometric/data/data.py:453\u001b[0m, in \u001b[0;36mData.__init__\u001b[0;34m(self, x, edge_index, edge_attr, y, pos, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    444\u001b[0m     x: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# `Data` doesn't support group_name, so we need to adjust `TensorAttr`\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# accordingly here to avoid requiring `group_name` to be set:\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor_attr_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataTensorAttr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# `Data` doesn't support edge_type, so we need to adjust `EdgeAttr`\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;66;03m# accordingly here to avoid requiring `edge_type` to be set:\u001b[39;00m\n\u001b[1;32m    457\u001b[0m     GraphStore\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, edge_attr_cls\u001b[38;5;241m=\u001b[39mDataEdgeAttr)\n",
      "File \u001b[0;32m~/miniconda3/envs/representer/lib/python3.9/site-packages/torch_geometric/data/feature_store.py:262\u001b[0m, in \u001b[0;36mFeatureStore.__init__\u001b[0;34m(self, tensor_attr_cls)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFeatureStore\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"An abstract base class to access features from a remote feature store.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m            (default: :obj:`None`)\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_attr_cls: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_tensor_attr_cls\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tensor_attr_cls \u001b[38;5;129;01mor\u001b[39;00m TensorAttr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Create unlearners \n",
    "unlearners = []\n",
    "unlearners_cfg = global_ctx.config.unlearners\n",
    "for un in unlearners_cfg:\n",
    "    current = Local(un)\n",
    "    current.dataset = data_manager\n",
    "    current.predictor = copy.deepcopy(predictor)\n",
    "    unlearners.append( global_ctx.factory.get_object(current) )\n",
    "\n",
    "#Evaluator\n",
    "current = Local(global_ctx.config.evaluator)\n",
    "current.unlearners = unlearners\n",
    "evaluator = global_ctx.factory.get_object(current)\n",
    "\n",
    "# Evaluations\n",
    "for unlearner in unlearners:\n",
    "    global_ctx.logger.info(f'''{bcolors.OKGREEN}####\\t\\t Evaluating Unlearner {unlearner.__class__.__name__} \\t\\t####{bcolors.ENDC}''')\n",
    "    evaluator.evaluate(unlearner,predictor)\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "representer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
